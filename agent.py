import sqlite3
from operator import itemgetter
import concurrent.futures
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.utilities import SQLDatabase
from langchain_openai import ChatOpenAI

# Setup Database and LLM
db = SQLDatabase.from_uri("sqlite:///mlb_batting_stats.db")
# locally hosted llm model (specifically: LFM2-8B-A1B-Q4_K_M)
llm = ChatOpenAI(
    base_url="http://localhost:8080/v1",
    api_key="not-needed",
    model="llama3",
    temperature=0,
    request_timeout=20 
)

# SQL Generation Prompt
# here hardcode the schema to ensure the model doesn't guess names
# sql_prompt is the instruction sheet for llm
sql_prompt = ChatPromptTemplate.from_template("""
You are a SQL expert. Given the following database schema, write a valid SQLite query.
Table: stats
Columns: mlbid, hr, name, year
Rules:
- Use 'mlbid' for player IDs and 'hr' for home runs.
- Use 'name' for player name.
- Return ONLY the SQL query. Do not include markdown or backticks.

Question: {question}
SQL Query:""")

# Define the Execution Function
def run_query(query):
    # Clean the query string in case the LLM adds markdown
    query = query.strip().replace("```sql", "").replace("```", "")
    return db.run(query)

# Natural Language Answer Prompt
answer_prompt = ChatPromptTemplate.from_template("""
Given the user question, the SQL query used, and the database result, 
provide a conversational answer.

Question: {question}
SQL Query: {query}
SQL Result: {result}
Answer:""")

# The "Full Chain" Assembly
# pipe (|) operator is part of LCEL (LangChain Expression Language)
# this pipes the output of one step into the next
# question goes into sql_prompt then llm then is parsed
# StrOutputParser removes the extra text generated by the llm
sql_chain = sql_prompt | llm | StrOutputParser() 

full_chain = (
    RunnablePassthrough.assign(query=sql_chain) # merger: keeps original question and adds SQL string
    .assign(result=lambda x: run_query(x["query"])) #run_query runs the sql query and outputs the rows
    | answer_prompt
    | llm
    | StrOutputParser()
)


def get_response(user_question):
    """
    Runs the chain with a hard timeout (e.g., 15 seconds).
    If it takes too long, it kills the process and returns the fallback message.
    """
    TIMEOUT_SECONDS = 15
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(full_chain.invoke, {"question": user_question})
        try:
            return future.result(timeout=TIMEOUT_SECONDS)
        except concurrent.futures.TimeoutError:
            return "I couldn't find an answer (the request timed out)."
        except Exception as e:
            return f"I ran into an error: {e}"

# For testing
if __name__ == "__main__":
    print(get_response("What is the total number of home runs hit in 2023?"))

